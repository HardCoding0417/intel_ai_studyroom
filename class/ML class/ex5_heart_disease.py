# -*- coding: utf-8 -*-
"""ex5_heart_disease.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HFJBwXEuMvYH3axKAACKUX_dv20AXNqd
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

column_name = ['age', 'sex', 'cp', 'treshbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'HeartDisease']
raw_data = pd.read_excel('datasets/heart-disease.xlsx', header=None, names=column_name)
print(raw_data.head())

print(raw_data.describe())

raw_data.info()

clean_data = raw_data.replace('?', np.nan)
clean_data = clean_data.dropna()
clean_data.info()

keep = column_name.pop()
print(keep)
print(column_name)

training_data = clean_data[column_name]
target = clean_data[[keep]]
print(training_data.head())
print(target.head())

print(target[keep].sum())
print(target[keep].mean()) # 불균형이 심하면 도움이 안 됨.

from sklearn.preprocessing import StandardScaler # standardization

scaler = StandardScaler()
scaled_data = scaler.fit_transform(training_data)
scaled_data = pd.DataFrame(scaled_data, columns=column_name)
print(scaled_data.head())

print(scaled_data.describe().T)

boxplot = scaled_data.boxplot(column=column_name, showmeans=True)
plt.show()

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(scaled_data, target, test_size=0.3)
print(X_train.shape)
print(Y_train.shape)
print(X_test.shape)
print(Y_test.shape)

model = Sequential()
model.add(Dense(512, input_dim=13, activation='relu'))
model.add(Dropout(0.25)) # do not learn for 25% probability; not a layer
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))
model.summary()

model.compile(loss='mse', optimizer='adam', metrics=['binary_accuracy'])
fit_hist = model.fit(
    X_train, Y_train, batch_size=50, epochs=50, # batch_size: change parameters for 50 data_cnt in an epoch
    validation_split=0.2, verbose=1 # validation_split: validation for each epoch; prevents overfitting by observing accuracy
)

plt.plot(fit_hist.history['binary_accuracy'])
plt.plot(fit_hist.history['val_binary_accuracy'])
plt.show()

score = model.evaluate(X_test, Y_test, verbose=0)
print('Keras DNN model loss:', score[0])
print('Keras DNN model accuracy:', score[1])

from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score

pred = model.predict(X_test)
pred = pred > 0.5
print(confusion_matrix(Y_test, pred)) # row: actual(Y_test), col: prediction(pred)
print(f1_score(Y_test, pred, average='micro'))
