# -*- coding: utf-8 -*-
"""ex2_principles_of_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mKV4-UwQFCk5DmNpPwq9ndQU3Imo86Ri

#그래프 연산
"""

import numpy as np

class add_graph:
  def __init__(self):
    pass
  def forward(self, x, y):
    return x + y
  def backward(self, dout):
    dx = 1 * dout
    dy = 1 * dout
    return dx, dy

class mult_graph:
  def __init__(self):
    self.x = None
    self.y = None
  def forward(self, x, y):
    self.x = x
    self.y = y
    return x * y
  def backward(self, dout):
    dx = self.y * dout
    dy = self.x * dout
    return dx, dy

class mse_graph:
  def __init__(self):
    self.loss = None
    self.x = None
    self.y = None
    self.t = None
  def forward(self, y, t):
    self.t = t
    self.y = y
    self.loss = np.square(t - y).sum() / t.shape[0]
    return self.loss
  def backward(self, x, dout = 1):
    data_size = self.t.shape[0]
    dweight_mse = ((self.y - self.t) * x).sum() * 2 / data_size
    dbias_mse = (self.y - self.t).sum() * 2 / data_size
    return dweight_mse, dbias_mse

apple = 100
apple_cnt = 2
orange = 150
orange_cnt = 3
tax = 1.1

mult_apple_graph = mult_graph()
mult_orange_graph = mult_graph()
add_apple_orange_graph = add_graph()
mult_tax_graph = mult_graph()

apple_price = mult_apple_graph.forward(apple, apple_cnt)
orange_price = mult_orange_graph.forward(orange, orange_cnt)
price = add_apple_orange_graph.forward(apple_price, orange_price)
taxed_price = mult_tax_graph.forward(price, tax)

print(f'{taxed_price:.15g}')

dtaxed_price = 1
dprice, dtax = mult_tax_graph.backward(dtaxed_price)
dapple_price, dorange_price = add_apple_orange_graph.backward(dprice)
dorange, dorange_cnt = mult_orange_graph.backward(dorange_price)
dapple, dapple_cnt = mult_apple_graph.backward(dapple_price)

print('dapple', dapple)
print('dapple_num', dapple_cnt)
print('dorange', dorange)
print('dorange_num', dorange_cnt)

def celsius_to_fahrenheit(x):
  return 1.8 * x + 32

# initial parameters
weight = np.random.uniform(0, 5, 1)[0]
bias = 0

data_C = np.arange(1, 100)
data_F = celsius_to_fahrenheit(data_C)
scaled_data_C = data_C / 100
scaled_data_F = data_F / 100

weight_graph = mult_graph()
bias_graph = add_graph()

# prediction
weighted_data = weight_graph.forward(weight, scaled_data_C)
predicted_data = bias_graph.forward(weighted_data, bias)

# the amplitude of weight/bias' effect on prediction
dpredicted_data = 1
dweighted_data, dbias = bias_graph.backward(dpredicted_data)
dweight, dscaled_data_C = weight_graph.backward(dweighted_data)
print(dweight)
print(dbias)

# Calculate Mean Squared Error(MSE)
mseGraph = mse_graph()
mse = mseGraph.forward(predicted_data, scaled_data_F)

# Dirrentiate MSE with respect to weight and bias
weight_mse_gradient, bias_mse_gradient = mseGraph.backward(scaled_data_C)
print(weight_mse_gradient)
print(bias_mse_gradient)

learning_rate = 0.1
# weight_mse_gradient: The more distance with ideal weight the predicted weight has, the larger value the derivative of MSE with respect to weight has
# np.average(dweight): We want learned_weight to change its value as much as the amplitude of weight's effect on prediction
learned_weight = weight - learning_rate * weight_mse_gradient * np.average(dweight)
print('weight', weight)
print('learned_weight', learned_weight)

learned_bias = bias - learning_rate * bias_mse_gradient * dbias
print('bias', bias)
print('learned_bias', learned_bias)

# Choi Myeongsu



# learning_rate = 0.1
# learned_weight = weight
# learned_bias = bias

# for i in range(1000):
#   weighted_data = weight_graph.forward(learned_weight, scaled_data_C)
#   predict_data = bias_graph.forward(weighted_data, learned_bias)

#   mseGraph = mse_graph()
#   mse = mseGraph.forward(predict_data, scaled_data_F)
#   weight_mse_gradient, _ = mseGraph.backward(scaled_data_C)

#   learned_weight -= learning_rate * weight_mse_gradient * np.average(dweight)


#   weighted_data = weight_graph.forward(learned_weight, scaled_data_C)
#   predict_data = bias_graph.forward(weighted_data, learned_bias)

#   mseGraph = mse_graph()
#   mse = mseGraph.forward(predict_data, scaled_data_F)
#   _, bias_mse_gradient = mseGraph.backward(scaled_data_C)

#   learned_bias -= learning_rate * bias_mse_gradient * dbias

# print(f"{learned_weight:.15g}")
# print(f"{learned_bias:.15g}")

error_list = []
weight_list = []
bias_list = []

for i in range(1000):
  #forward
  weighted_data = weight_graph.forward(weight, scaled_data_C)
  predicted_data = bias_graph.forward(weighted_data, bias)
  #backward
  dpredict_data = 1
  dweighted_data, dbias = bias_graph.backward(dpredict_data)
  dweight, dscaled_data_C = weight_graph.backward(dweighted_data)
  #mse
  mse = mseGraph.forward(predicted_data, scaled_data_F)
  error_list.append(mse)
  weight_mse_gradient, bias_mse_gradient = mseGraph.backward(scaled_data_C)
  #learning
  weight_list.append(weight)
  weight -= learning_rate * weight_mse_gradient * np.average(dweight)
  bias_list.append(bias)
  bias -= learning_rate * bias_mse_gradient * dbias
weight_list.append(weight)
bias_list.append(bias)

print(weight)
print(bias)

print(error_list[-1])

import matplotlib.pyplot as plt

plt.plot(error_list)
plt.show()

plt.plot(weight_list)
plt.show()

plt.plot(bias_list)
plt.show()