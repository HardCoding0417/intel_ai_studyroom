# -*- coding: utf-8 -*-
"""ex6_titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16BNqs6bG87Q75fZO3G1xJcPxN85y9OOu
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn import preprocessing

# pd.set_option('display.max_columns', 6)
# pd.set_option('display.unicode.east_asian', True)

df = sns.load_dataset('titanic')
df

deck = df['deck'].value_counts(dropna=False)
print(deck)

print(df.head().isnull()) # df.info()

print(df.head().notnull())

print(df.isnull().sum()) # cannot use 'deck' / cannot drop 'age'

df.dropna(axis=1, thresh=500, inplace=True)
print(df.columns)

df_age_removed = df.dropna(subset=['age'], how='any', axis=0) # how='all': all NaN in subset
df_age_removed.info()

mean_age = df['age'].mean() # mean except for NaN
print(mean_age)
df['age'].fillna(mean_age, inplace=True) # or fill with the mean age of adult_male, not_adult_male, and female
df.head(10)

embark_town_cnt = df['embark_town'].value_counts(dropna=True)
print(embark_town_cnt)
embark_town_mode = embark_town_cnt.idxmax()

df_mode = df['embark_town'].fillna(embark_town_mode)
df_mode.value_counts()

print(df_mode[825:830])
print(df[825:830])

df['embark_town'].fillna(method='ffill', inplace=True) # fill with previous value(forward/backward) (e.g.] Excel)
print(df[825:830])

df.info()

df.drop(['embarked', 'alive'], axis='columns', inplace=True)
df.info()

print(df.isnull().sum())

target_data = df[['survived']]
target_data

training_data = df.drop(['survived'], axis=1)
training_data.columns

training_data # age, fare: ratio scale

ratio_scale_data = training_data[['age', 'fare']]

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_data = scaler.fit_transform(ratio_scale_data)
scaled_data

ratio_scale_data = pd.DataFrame(scaled_data, columns=ratio_scale_data.columns)
ratio_scale_data

training_data.drop(['age', 'fare'], axis='columns', inplace=True)
training_data

onehot_data = pd.get_dummies(training_data, columns=training_data.columns)
onehot_data.info()

training_data = pd.concat([ratio_scale_data, onehot_data], axis=1)
training_data.info()

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(training_data, target_data, test_size=0.2)

print(X_train.shape)
print(Y_train.shape)
print(X_test.shape)
print(Y_test.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential()
model.add(Dense(128, input_dim=34, activation='relu'))
model.add(Dropout(0.02))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.02))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.02))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.02))
model.add(Dense(1, activation='sigmoid'))
model.summary()

model.compile(optimizer='adam', loss='mse', metrics=['binary_accuracy'])
fit_hist = model.fit(training_data, target_data,
          batch_size=50, epochs=30, validation_split=0.2, verbose=1)

import matplotlib.pyplot as plt
plt.plot(fit_hist.history['binary_accuracy'])
plt.plot(fit_hist.history['val_binary_accuracy'])
plt.show()

score = model.evaluate(X_test, Y_test, verbose=0)
print('loss', score[0])
print('accuracy', score[1])
